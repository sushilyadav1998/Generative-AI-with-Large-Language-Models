# Generative-AI-with-Large-Language-Models
Generative AI with Large Language Models Coursera course

This course covers the fundamentals of how generative AI works, and how to deploy it in real-world applications.
Topics covered:

- LLM Usecase
- Transformers Architecture
- Prompting and Promt Engineering
- Generative AI project lifecycle
- Computational challenges
- Scaling laws and compute optimal models
- Fine tuning on a single task
- Multitask instruction fine tuning
- Model evaluation and benchmarks
- Parameter efficient fine-tuning (PEFT) (LoRA and Soft prompts)
- Reinforcement learning from human feedback (RLHF)
- Proximal policy optimization
- RLHF: Reward hacking
- Model optimizations for deployment
- Helping LLMs reason and plan with chain-of-thought
- Program-aided language models (PAL)
- ReAct: Combining reasoning and action
- AWS Sagemaker JumpStart
